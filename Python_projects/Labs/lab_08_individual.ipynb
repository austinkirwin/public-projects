{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 207 Lab Assignment 8 - Individual Part\n",
    "\n",
    "\n",
    "# <u>Case Study</u>: Predicting Coffee <font color=\"blue\">Balance</font> *for New Coffee Brands*\n",
    "\n",
    "\n",
    "\n",
    "### Coffee Dataset Information\n",
    "\n",
    "In this individual assignment we will return to the `coffee.csv` dataset. Information about the variables in this dataset can be found here: https://corgis-edu.github.io/corgis/csv/coffee/\n",
    "\n",
    "\n",
    "### Research Goals\n",
    "\n",
    "In this individual assignment we would ideally like to pursue multiple research goals.\n",
    "\n",
    "#### Main Research Goal\n",
    "\n",
    "Our main research goal will be to create a predictive model that effectively predicts the <font color=\"blue\">Balance</font> of *new coffee brands*.\n",
    "\n",
    "\n",
    "#### Secondary Research Goals\n",
    "\n",
    "Ideally, the predictive model that we select will also be able to accurately reflect the relationship between the explanatory variables and the response variable <font color=\"blue\">Balance</font>.\n",
    "\n",
    "\n",
    "## Points\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<table style=\"border: none;border-collapse: collapse;width:102pt;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;width:51pt;\">Problem</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;border-left:none;width:51pt;\">Points</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.6.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.6.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.7</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.5.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.5.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.6</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Tutorial</u>: Iteratively Updating a List of Lists\n",
    "\n",
    "You may need this tutorial in this assignment.\n",
    "\n",
    "Suppose we wanted to iterate through a range of `i` values going from 0, 0.5, 1, 1.5, ..., 19.5.\n",
    "\n",
    "For each of these `i` values we wanted to add a sublist `[i, 3*i]` to a list of lists. \n",
    "\n",
    "We can do so as follows using the code below.\n",
    "1. The **np.arange(a, b, c)** function creates a list of values going from `a` to `b-c`, using a step size of `c`.\n",
    "2. The **.append()** function adds the given value in the parantheses to the corresponding list that the **.append()** function corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " [0.5, 1.5],\n",
       " [1.0, 3.0],\n",
       " [1.5, 4.5],\n",
       " [2.0, 6.0],\n",
       " [2.5, 7.5],\n",
       " [3.0, 9.0],\n",
       " [3.5, 10.5],\n",
       " [4.0, 12.0],\n",
       " [4.5, 13.5],\n",
       " [5.0, 15.0],\n",
       " [5.5, 16.5],\n",
       " [6.0, 18.0],\n",
       " [6.5, 19.5],\n",
       " [7.0, 21.0],\n",
       " [7.5, 22.5],\n",
       " [8.0, 24.0],\n",
       " [8.5, 25.5],\n",
       " [9.0, 27.0],\n",
       " [9.5, 28.5],\n",
       " [10.0, 30.0],\n",
       " [10.5, 31.5],\n",
       " [11.0, 33.0],\n",
       " [11.5, 34.5],\n",
       " [12.0, 36.0],\n",
       " [12.5, 37.5],\n",
       " [13.0, 39.0],\n",
       " [13.5, 40.5],\n",
       " [14.0, 42.0],\n",
       " [14.5, 43.5],\n",
       " [15.0, 45.0],\n",
       " [15.5, 46.5],\n",
       " [16.0, 48.0],\n",
       " [16.5, 49.5],\n",
       " [17.0, 51.0],\n",
       " [17.5, 52.5],\n",
       " [18.0, 54.0],\n",
       " [18.5, 55.5],\n",
       " [19.0, 57.0],\n",
       " [19.5, 58.5]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "temp_list=[]\n",
    "for i in np.arange(0,20,0.5):\n",
    "    temp_list.append([i, 3*i])\n",
    "temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this list of lists into a dataframe with the column names `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.5</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.5</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.5</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.5</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.5</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.5</td>\n",
       "      <td>31.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.5</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.5</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.5</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15.5</td>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16.5</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17.5</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.5</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.5</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a     b\n",
       "0    0.0   0.0\n",
       "1    0.5   1.5\n",
       "2    1.0   3.0\n",
       "3    1.5   4.5\n",
       "4    2.0   6.0\n",
       "5    2.5   7.5\n",
       "6    3.0   9.0\n",
       "7    3.5  10.5\n",
       "8    4.0  12.0\n",
       "9    4.5  13.5\n",
       "10   5.0  15.0\n",
       "11   5.5  16.5\n",
       "12   6.0  18.0\n",
       "13   6.5  19.5\n",
       "14   7.0  21.0\n",
       "15   7.5  22.5\n",
       "16   8.0  24.0\n",
       "17   8.5  25.5\n",
       "18   9.0  27.0\n",
       "19   9.5  28.5\n",
       "20  10.0  30.0\n",
       "21  10.5  31.5\n",
       "22  11.0  33.0\n",
       "23  11.5  34.5\n",
       "24  12.0  36.0\n",
       "25  12.5  37.5\n",
       "26  13.0  39.0\n",
       "27  13.5  40.5\n",
       "28  14.0  42.0\n",
       "29  14.5  43.5\n",
       "30  15.0  45.0\n",
       "31  15.5  46.5\n",
       "32  16.0  48.0\n",
       "33  16.5  49.5\n",
       "34  17.0  51.0\n",
       "35  17.5  52.5\n",
       "36  18.0  54.0\n",
       "37  18.5  55.5\n",
       "38  19.0  57.0\n",
       "39  19.5  58.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(temp_list, columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Coffee Dataset\n",
    "\n",
    "### 1.1. Reading the csv\n",
    "\n",
    "1. Read the `coffee.csv` into a dataframe. The strings that are used to represent missing values in this csv file are represented with 'nan'. Luckily, 'nan' is one of the string values that the **pd.read_csv()** function is automatically programmed to detect as a missing value and thus convert into a NaN type object.\n",
    "2. Show the first 5 rows.\n",
    "3. Show how many rows this dataframe has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Country</th>\n",
       "      <th>Location_Region</th>\n",
       "      <th>Location_Altitude_Min</th>\n",
       "      <th>Location_Altitude_Max</th>\n",
       "      <th>Location_Altitude_Average</th>\n",
       "      <th>Year</th>\n",
       "      <th>Data_Owner</th>\n",
       "      <th>Data_Type_Species</th>\n",
       "      <th>Data_Type_Variety</th>\n",
       "      <th>Data_Type_Processing method</th>\n",
       "      <th>...</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <th>Data_Scores_Total</th>\n",
       "      <th>Data_Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>kona</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>kona pacific farmers cooperative</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.25</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>sul de minas - carmo de minas</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>jacques pereira carneiro</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>Yellow Bourbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>86.17</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>sul de minas - carmo de minas</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>jacques pereira carneiro</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>Yellow Bourbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>86.17</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>sidamo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>ethiopia commodity exchange</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.08</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>sidamo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>ethiopia commodity exchange</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>83.83</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location_Country                Location_Region  Location_Altitude_Min  \\\n",
       "0    United States                           kona                      0   \n",
       "1           Brazil  sul de minas - carmo de minas                     12   \n",
       "2           Brazil  sul de minas - carmo de minas                     12   \n",
       "3         Ethiopia                         sidamo                      0   \n",
       "4         Ethiopia                         sidamo                      0   \n",
       "\n",
       "   Location_Altitude_Max  Location_Altitude_Average  Year  \\\n",
       "0                      0                          0  2010   \n",
       "1                     12                         12  2010   \n",
       "2                     12                         12  2010   \n",
       "3                      0                          0  2010   \n",
       "4                      0                          0  2010   \n",
       "\n",
       "                         Data_Owner Data_Type_Species Data_Type_Variety  \\\n",
       "0  kona pacific farmers cooperative           Arabica               NaN   \n",
       "1          jacques pereira carneiro           Arabica    Yellow Bourbon   \n",
       "2          jacques pereira carneiro           Arabica    Yellow Bourbon   \n",
       "3       ethiopia commodity exchange           Arabica               NaN   \n",
       "4       ethiopia commodity exchange           Arabica               NaN   \n",
       "\n",
       "  Data_Type_Processing method  ...  Data_Scores_Flavor  \\\n",
       "0                         NaN  ...                8.42   \n",
       "1                         NaN  ...                7.92   \n",
       "2                         NaN  ...                7.92   \n",
       "3                         NaN  ...                8.00   \n",
       "4                         NaN  ...                7.83   \n",
       "\n",
       "   Data_Scores_Aftertaste  Data_Scores_Acidity  Data_Scores_Body  \\\n",
       "0                    8.08                 7.75              7.67   \n",
       "1                    7.92                 7.75              8.33   \n",
       "2                    8.00                 7.75              7.92   \n",
       "3                    7.83                 8.00              7.92   \n",
       "4                    7.58                 8.00              7.83   \n",
       "\n",
       "   Data_Scores_Balance  Data_Scores_Uniformity  Data_Scores_Sweetness  \\\n",
       "0                 7.83                    10.0                   10.0   \n",
       "1                 8.00                    10.0                   10.0   \n",
       "2                 8.00                    10.0                   10.0   \n",
       "3                 7.83                    10.0                   10.0   \n",
       "4                 7.50                    10.0                   10.0   \n",
       "\n",
       "   Data_Scores_Moisture  Data_Scores_Total  Data_Color  \n",
       "0                  0.00              86.25     Unknown  \n",
       "1                  0.08              86.17     Unknown  \n",
       "2                  0.01              86.17     Unknown  \n",
       "3                  0.00              85.08     Unknown  \n",
       "4                  0.10              83.83     Unknown  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coffee.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dropping NaN Values\n",
    "\n",
    "We only intend to use the following variables in this dataframe:\n",
    "* `Data_Scores_Aroma`\n",
    "* `Data_Scores_Flavor`\n",
    "* `Data_Scores_Aftertaste`\n",
    "* `Data_Scores_Acidity`\n",
    "* `Data_Scores_Body`\n",
    "* `Data_Scores_Balance`\n",
    "* `Data_Scores_Uniformity`\n",
    "* `Data_Scores_Sweetness`\n",
    "* `Data_Scores_Moisture`.\n",
    "\n",
    "1. Create a dataframe with just these variables.\n",
    "2. Then drop all rows from this dataframe that have a NaN value.\n",
    "3. How many rows did you drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989\n"
     ]
    }
   ],
   "source": [
    "dfb = df[[\"Data_Scores_Aroma\", \"Data_Scores_Flavor\", \"Data_Scores_Aftertaste\", \"Data_Scores_Acidity\", \"Data_Scores_Body\", \"Data_Scores_Balance\", \"Data_Scores_Uniformity\", \"Data_Scores_Sweetness\", \"Data_Scores_Moisture\"]]\n",
    "orig_rows = dfb.shape[0]\n",
    "print(orig_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = dfb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_rows - dfb.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Dropping a Large Outlier\n",
    "\n",
    "This dataset has a prominent outlier with an `Aroma` rating that is equal to 0. Drop this observation from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb = dfb[dfb['Data_Scores_Aroma'] > 0]\n",
    "dfb.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Training and Test Datasets\n",
    "\n",
    "We intend to build linear regression models that will predict the <font color=\"blue\">Balance</font> of *new coffee brands* using some of the following explanatory variables.\n",
    "\n",
    "* `Data_Scores_Aroma`\n",
    "* `Data_Scores_Aftertaste`\n",
    "* `Data_Scores_Acidity`\n",
    "* `Data_Scores_Body`\n",
    "* `Data_Scores_Flavor`\n",
    "* `Data_Scores_Uniformity`\n",
    "* `Data_Scores_Sweetness`\n",
    "* `Data_Scores_Moisture`\n",
    "\n",
    "\n",
    "Using some combination of these explanatory variables, we'd like to build and select a linear regression model which we can infer might perform well when it comes to predicting the `Balance` of *new coffee brands*. Thus, let's create a training and a test dataset from our cleaned dataframe from 1.3.\n",
    "\n",
    "Use a random state of `555` to do this. Your training dataset should be 80% of observations from your cleaned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(dfb, test_size=.2, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
      "871               7.50                7.58                    7.42   \n",
      "432               7.58                7.33                    7.17   \n",
      "524               7.33                7.58                    7.50   \n",
      "192               8.00                7.75                    7.33   \n",
      "327               7.25                7.33                    7.00   \n",
      "..                 ...                 ...                     ...   \n",
      "381               7.92                7.75                    7.67   \n",
      "580               7.67                7.67                    7.67   \n",
      "33                7.50                7.42                    7.25   \n",
      "686               7.50                7.17                    6.83   \n",
      "410               7.50                7.50                    7.50   \n",
      "\n",
      "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Balance  \\\n",
      "871                 7.83              7.67                 7.58   \n",
      "432                 7.33              7.25                 8.58   \n",
      "524                 7.75              7.75                 7.67   \n",
      "192                 7.33              7.08                 7.67   \n",
      "327                 7.00              7.25                 7.08   \n",
      "..                   ...               ...                  ...   \n",
      "381                 7.67              7.83                 7.92   \n",
      "580                 7.92              7.50                 7.67   \n",
      "33                  7.17              7.17                 7.75   \n",
      "686                 7.50              7.17                 7.17   \n",
      "410                 7.67              7.67                 7.67   \n",
      "\n",
      "     Data_Scores_Uniformity  Data_Scores_Sweetness  Data_Scores_Moisture  \n",
      "871                   10.00                  10.00                  0.11  \n",
      "432                   10.00                  10.00                  0.10  \n",
      "524                   10.00                   7.75                  0.12  \n",
      "192                    9.33                  10.00                  0.11  \n",
      "327                   10.00                   8.00                  0.12  \n",
      "..                      ...                    ...                   ...  \n",
      "381                   10.00                  10.00                  0.11  \n",
      "580                   10.00                  10.00                  0.00  \n",
      "33                    10.00                  10.00                  0.11  \n",
      "686                   10.00                  10.00                  0.11  \n",
      "410                   10.00                  10.00                  0.10  \n",
      "\n",
      "[790 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.42</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>8.25</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>7.42</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "268               7.58                7.33                    7.42   \n",
       "626               7.67                7.42                    7.33   \n",
       "1                 8.17                7.92                    7.92   \n",
       "646               7.50                7.50                    7.33   \n",
       "937               7.67                7.75                    7.50   \n",
       "..                 ...                 ...                     ...   \n",
       "236               7.50                7.42                    7.33   \n",
       "431               7.58                7.83                    7.75   \n",
       "883               7.50                7.58                    7.42   \n",
       "533               8.25                8.50                    8.25   \n",
       "470               7.42                7.33                    7.17   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Balance  \\\n",
       "268                 7.25              7.50                 7.50   \n",
       "626                 7.58              7.50                 7.50   \n",
       "1                   7.75              8.33                 8.00   \n",
       "646                 7.33              7.33                 7.33   \n",
       "937                 7.58              7.58                 7.67   \n",
       "..                   ...               ...                  ...   \n",
       "236                 7.42              7.42                 7.42   \n",
       "431                 7.75              7.42                 8.00   \n",
       "883                 7.50              7.75                 7.33   \n",
       "533                 8.50              8.42                 8.33   \n",
       "470                 7.58              7.42                 7.50   \n",
       "\n",
       "     Data_Scores_Uniformity  Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "268                    9.33                   10.0                  0.11  \n",
       "626                   10.00                   10.0                  0.12  \n",
       "1                     10.00                   10.0                  0.08  \n",
       "646                   10.00                   10.0                  0.10  \n",
       "937                   10.00                   10.0                  0.10  \n",
       "..                      ...                    ...                   ...  \n",
       "236                   10.00                   10.0                  0.11  \n",
       "431                    9.33                   10.0                  0.10  \n",
       "883                   10.00                   10.0                  0.11  \n",
       "533                   10.00                   10.0                  0.12  \n",
       "470                   10.00                   10.0                  0.12  \n",
       "\n",
       "[198 rows x 9 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Features Matrices and Target Arrays\n",
    "\n",
    "Use your training dataset and test dataset to create the following.\n",
    "* Training features matrix\n",
    "* Training target array\n",
    "* Test features matrix\n",
    "* Test target array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>7.33</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.08</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>7.25</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "871               7.50                7.58                    7.42   \n",
       "432               7.58                7.33                    7.17   \n",
       "524               7.33                7.58                    7.50   \n",
       "192               8.00                7.75                    7.33   \n",
       "327               7.25                7.33                    7.00   \n",
       "..                 ...                 ...                     ...   \n",
       "381               7.92                7.75                    7.67   \n",
       "580               7.67                7.67                    7.67   \n",
       "33                7.50                7.42                    7.25   \n",
       "686               7.50                7.17                    6.83   \n",
       "410               7.50                7.50                    7.50   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Uniformity  \\\n",
       "871                 7.83              7.67                   10.00   \n",
       "432                 7.33              7.25                   10.00   \n",
       "524                 7.75              7.75                   10.00   \n",
       "192                 7.33              7.08                    9.33   \n",
       "327                 7.00              7.25                   10.00   \n",
       "..                   ...               ...                     ...   \n",
       "381                 7.67              7.83                   10.00   \n",
       "580                 7.92              7.50                   10.00   \n",
       "33                  7.17              7.17                   10.00   \n",
       "686                 7.50              7.17                   10.00   \n",
       "410                 7.67              7.67                   10.00   \n",
       "\n",
       "     Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "871                  10.00                  0.11  \n",
       "432                  10.00                  0.10  \n",
       "524                   7.75                  0.12  \n",
       "192                  10.00                  0.11  \n",
       "327                   8.00                  0.12  \n",
       "..                     ...                   ...  \n",
       "381                  10.00                  0.11  \n",
       "580                  10.00                  0.00  \n",
       "33                   10.00                  0.11  \n",
       "686                  10.00                  0.11  \n",
       "410                  10.00                  0.10  \n",
       "\n",
       "[790 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature = df_train.drop(['Data_Scores_Balance'], axis=1)\n",
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871    7.58\n",
       "432    8.58\n",
       "524    7.67\n",
       "192    7.67\n",
       "327    7.08\n",
       "       ... \n",
       "381    7.92\n",
       "580    7.67\n",
       "33     7.75\n",
       "686    7.17\n",
       "410    7.67\n",
       "Name: Data_Scores_Balance, Length: 790, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = df_train['Data_Scores_Balance']\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.42</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>8.25</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.42</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>7.42</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "268               7.58                7.33                    7.42   \n",
       "626               7.67                7.42                    7.33   \n",
       "1                 8.17                7.92                    7.92   \n",
       "646               7.50                7.50                    7.33   \n",
       "937               7.67                7.75                    7.50   \n",
       "..                 ...                 ...                     ...   \n",
       "236               7.50                7.42                    7.33   \n",
       "431               7.58                7.83                    7.75   \n",
       "883               7.50                7.58                    7.42   \n",
       "533               8.25                8.50                    8.25   \n",
       "470               7.42                7.33                    7.17   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Uniformity  \\\n",
       "268                 7.25              7.50                    9.33   \n",
       "626                 7.58              7.50                   10.00   \n",
       "1                   7.75              8.33                   10.00   \n",
       "646                 7.33              7.33                   10.00   \n",
       "937                 7.58              7.58                   10.00   \n",
       "..                   ...               ...                     ...   \n",
       "236                 7.42              7.42                   10.00   \n",
       "431                 7.75              7.42                    9.33   \n",
       "883                 7.50              7.75                   10.00   \n",
       "533                 8.50              8.42                   10.00   \n",
       "470                 7.58              7.42                   10.00   \n",
       "\n",
       "     Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "268                   10.0                  0.11  \n",
       "626                   10.0                  0.12  \n",
       "1                     10.0                  0.08  \n",
       "646                   10.0                  0.10  \n",
       "937                   10.0                  0.10  \n",
       "..                     ...                   ...  \n",
       "236                   10.0                  0.11  \n",
       "431                   10.0                  0.10  \n",
       "883                   10.0                  0.11  \n",
       "533                   10.0                  0.12  \n",
       "470                   10.0                  0.12  \n",
       "\n",
       "[198 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature = df_test.drop(['Data_Scores_Balance'], axis=1)\n",
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268    7.50\n",
       "626    7.50\n",
       "1      8.00\n",
       "646    7.33\n",
       "937    7.67\n",
       "       ... \n",
       "236    7.42\n",
       "431    8.00\n",
       "883    7.33\n",
       "533    8.33\n",
       "470    7.50\n",
       "Name: Data_Scores_Balance, Length: 198, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target = df_test['Data_Scores_Balance']\n",
    "test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Scaling the Features Matrices\n",
    "\n",
    "We'd like to be able to compare the magnitudes of our slopes in our linear regression models to try to infer the corresponding explanatory variable's importance when it comes to predicting coffee `balance`. \n",
    "\n",
    "So let's z-score scale our training features matrix as well as our test features matrix.\n",
    "\n",
    "#### 1.6.1. Scaling the Training Features Matrix\n",
    "\n",
    "Z-score scale each of the values in your TRAINING features matrix using the corresponding TRAINING data column means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.256288</td>\n",
       "      <td>0.170831</td>\n",
       "      <td>0.075484</td>\n",
       "      <td>0.878717</td>\n",
       "      <td>0.514866</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.369684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004306</td>\n",
       "      <td>-0.555680</td>\n",
       "      <td>-0.630392</td>\n",
       "      <td>-0.664125</td>\n",
       "      <td>-0.873453</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.149601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.791749</td>\n",
       "      <td>0.170831</td>\n",
       "      <td>0.301364</td>\n",
       "      <td>0.631862</td>\n",
       "      <td>0.779308</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>-3.314571</td>\n",
       "      <td>0.589767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.318599</td>\n",
       "      <td>0.664859</td>\n",
       "      <td>-0.178631</td>\n",
       "      <td>-0.664125</td>\n",
       "      <td>-1.435391</td>\n",
       "      <td>-1.026005</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.369684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.043731</td>\n",
       "      <td>-0.555680</td>\n",
       "      <td>-1.110387</td>\n",
       "      <td>-1.682402</td>\n",
       "      <td>-0.873453</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>-2.917753</td>\n",
       "      <td>0.589767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>1.066617</td>\n",
       "      <td>0.664859</td>\n",
       "      <td>0.781360</td>\n",
       "      <td>0.385008</td>\n",
       "      <td>1.043750</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.369684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>0.432375</td>\n",
       "      <td>0.781360</td>\n",
       "      <td>1.156429</td>\n",
       "      <td>-0.047072</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>-2.051231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>-0.256288</td>\n",
       "      <td>-0.294136</td>\n",
       "      <td>-0.404511</td>\n",
       "      <td>-1.157835</td>\n",
       "      <td>-1.137894</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.369684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>-0.256288</td>\n",
       "      <td>-1.020647</td>\n",
       "      <td>-1.590382</td>\n",
       "      <td>-0.139559</td>\n",
       "      <td>-1.137894</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.369684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>-0.256288</td>\n",
       "      <td>-0.061652</td>\n",
       "      <td>0.301364</td>\n",
       "      <td>0.385008</td>\n",
       "      <td>0.514866</td>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.149601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "0            -0.256288            0.170831                0.075484   \n",
       "1            -0.004306           -0.555680               -0.630392   \n",
       "2            -0.791749            0.170831                0.301364   \n",
       "3             1.318599            0.664859               -0.178631   \n",
       "4            -1.043731           -0.555680               -1.110387   \n",
       "..                 ...                 ...                     ...   \n",
       "785           1.066617            0.664859                0.781360   \n",
       "786           0.279174            0.432375                0.781360   \n",
       "787          -0.256288           -0.294136               -0.404511   \n",
       "788          -0.256288           -1.020647               -1.590382   \n",
       "789          -0.256288           -0.061652                0.301364   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Uniformity  \\\n",
       "0               0.878717          0.514866                0.325507   \n",
       "1              -0.664125         -0.873453                0.325507   \n",
       "2               0.631862          0.779308                0.325507   \n",
       "3              -0.664125         -1.435391               -1.026005   \n",
       "4              -1.682402         -0.873453                0.325507   \n",
       "..                   ...               ...                     ...   \n",
       "785             0.385008          1.043750                0.325507   \n",
       "786             1.156429         -0.047072                0.325507   \n",
       "787            -1.157835         -1.137894                0.325507   \n",
       "788            -0.139559         -1.137894                0.325507   \n",
       "789             0.385008          0.514866                0.325507   \n",
       "\n",
       "     Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0                 0.256797              0.369684  \n",
       "1                 0.256797              0.149601  \n",
       "2                -3.314571              0.589767  \n",
       "3                 0.256797              0.369684  \n",
       "4                -2.917753              0.589767  \n",
       "..                     ...                   ...  \n",
       "785               0.256797              0.369684  \n",
       "786               0.256797             -2.051231  \n",
       "787               0.256797              0.369684  \n",
       "788               0.256797              0.369684  \n",
       "789               0.256797              0.149601  \n",
       "\n",
       "[790 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaler = StandardScaler()\n",
    "scaled_exp = Scaler.fit_transform(train_feature)\n",
    "df_train_feature = pd.DataFrame(scaled_exp, columns=train_feature.columns)\n",
    "df_train_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2. Scaling the Test Features Matrix\n",
    "\n",
    "Z-score scale each of the values in your TEST features matrix using the corresponding TRAINING data column means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009743</td>\n",
       "      <td>-0.566273</td>\n",
       "      <td>0.051636</td>\n",
       "      <td>-1.022754</td>\n",
       "      <td>-0.037129</td>\n",
       "      <td>-0.898467</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.325317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304015</td>\n",
       "      <td>-0.311707</td>\n",
       "      <td>-0.201850</td>\n",
       "      <td>0.081273</td>\n",
       "      <td>-0.037129</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.567470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938856</td>\n",
       "      <td>1.102547</td>\n",
       "      <td>1.459895</td>\n",
       "      <td>0.650014</td>\n",
       "      <td>2.413391</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>-0.401142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.251832</td>\n",
       "      <td>-0.085427</td>\n",
       "      <td>-0.201850</td>\n",
       "      <td>-0.755111</td>\n",
       "      <td>-0.539043</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.083164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304015</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.276958</td>\n",
       "      <td>0.081273</td>\n",
       "      <td>0.199066</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.083164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-0.251832</td>\n",
       "      <td>-0.311707</td>\n",
       "      <td>-0.201850</td>\n",
       "      <td>-0.454013</td>\n",
       "      <td>-0.273324</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.325317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.847981</td>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.650014</td>\n",
       "      <td>-0.273324</td>\n",
       "      <td>-0.898467</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.083164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-0.251832</td>\n",
       "      <td>0.140854</td>\n",
       "      <td>0.051636</td>\n",
       "      <td>-0.186370</td>\n",
       "      <td>0.700979</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.325317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.200431</td>\n",
       "      <td>2.743081</td>\n",
       "      <td>2.389346</td>\n",
       "      <td>3.159165</td>\n",
       "      <td>2.679110</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.567470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.513406</td>\n",
       "      <td>-0.566273</td>\n",
       "      <td>-0.652493</td>\n",
       "      <td>0.081273</td>\n",
       "      <td>-0.273324</td>\n",
       "      <td>0.343490</td>\n",
       "      <td>0.271136</td>\n",
       "      <td>0.567470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "0             0.009743           -0.566273                0.051636   \n",
       "1             0.304015           -0.311707               -0.201850   \n",
       "2             1.938856            1.102547                1.459895   \n",
       "3            -0.251832           -0.085427               -0.201850   \n",
       "4             0.304015            0.621700                0.276958   \n",
       "..                 ...                 ...                     ...   \n",
       "193          -0.251832           -0.311707               -0.201850   \n",
       "194           0.009743            0.847981                0.981087   \n",
       "195          -0.251832            0.140854                0.051636   \n",
       "196           2.200431            2.743081                2.389346   \n",
       "197          -0.513406           -0.566273               -0.652493   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Uniformity  \\\n",
       "0              -1.022754         -0.037129               -0.898467   \n",
       "1               0.081273         -0.037129                0.343490   \n",
       "2               0.650014          2.413391                0.343490   \n",
       "3              -0.755111         -0.539043                0.343490   \n",
       "4               0.081273          0.199066                0.343490   \n",
       "..                   ...               ...                     ...   \n",
       "193            -0.454013         -0.273324                0.343490   \n",
       "194             0.650014         -0.273324               -0.898467   \n",
       "195            -0.186370          0.700979                0.343490   \n",
       "196             3.159165          2.679110                0.343490   \n",
       "197             0.081273         -0.273324                0.343490   \n",
       "\n",
       "     Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0                 0.271136              0.325317  \n",
       "1                 0.271136              0.567470  \n",
       "2                 0.271136             -0.401142  \n",
       "3                 0.271136              0.083164  \n",
       "4                 0.271136              0.083164  \n",
       "..                     ...                   ...  \n",
       "193               0.271136              0.325317  \n",
       "194               0.271136              0.083164  \n",
       "195               0.271136              0.325317  \n",
       "196               0.271136              0.567470  \n",
       "197               0.271136              0.567470  \n",
       "\n",
       "[198 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaler = StandardScaler()\n",
    "scaled_exp2 = Scaler.fit_transform(test_feature)\n",
    "df_test_feature = pd.DataFrame(scaled_exp2, columns=test_feature.columns)\n",
    "df_test_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Multicollinearity\n",
    "\n",
    "Will our full non-regularized linear regression model that uses all possible explanatory variables have an issue with multicollinearity? (Remember, we will train our models with the training dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.687381</td>\n",
       "      <td>0.583343</td>\n",
       "      <td>0.524785</td>\n",
       "      <td>0.616120</td>\n",
       "      <td>0.162246</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>-0.140139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <td>0.725166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.645804</td>\n",
       "      <td>0.740464</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.138560</td>\n",
       "      <td>-0.158118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <td>0.687381</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713362</td>\n",
       "      <td>0.644566</td>\n",
       "      <td>0.774139</td>\n",
       "      <td>0.229603</td>\n",
       "      <td>0.097145</td>\n",
       "      <td>-0.203983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <td>0.583343</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.713362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577561</td>\n",
       "      <td>0.642226</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>0.072401</td>\n",
       "      <td>-0.139417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <td>0.524785</td>\n",
       "      <td>0.645804</td>\n",
       "      <td>0.644566</td>\n",
       "      <td>0.577561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697203</td>\n",
       "      <td>0.120972</td>\n",
       "      <td>0.053079</td>\n",
       "      <td>-0.162159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <td>0.616120</td>\n",
       "      <td>0.740464</td>\n",
       "      <td>0.774139</td>\n",
       "      <td>0.642226</td>\n",
       "      <td>0.697203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238316</td>\n",
       "      <td>0.142841</td>\n",
       "      <td>-0.189901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <td>0.162246</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.229603</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>0.120972</td>\n",
       "      <td>0.238316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>0.024010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.138560</td>\n",
       "      <td>0.097145</td>\n",
       "      <td>0.072401</td>\n",
       "      <td>0.053079</td>\n",
       "      <td>0.142841</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <td>-0.140139</td>\n",
       "      <td>-0.158118</td>\n",
       "      <td>-0.203983</td>\n",
       "      <td>-0.139417</td>\n",
       "      <td>-0.162159</td>\n",
       "      <td>-0.189901</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Data_Scores_Aroma  Data_Scores_Flavor  \\\n",
       "Data_Scores_Aroma                1.000000            0.725166   \n",
       "Data_Scores_Flavor               0.725166            1.000000   \n",
       "Data_Scores_Aftertaste           0.687381            0.867073   \n",
       "Data_Scores_Acidity              0.583343            0.748506   \n",
       "Data_Scores_Body                 0.524785            0.645804   \n",
       "Data_Scores_Balance              0.616120            0.740464   \n",
       "Data_Scores_Uniformity           0.162246            0.240938   \n",
       "Data_Scores_Sweetness            0.046627            0.138560   \n",
       "Data_Scores_Moisture            -0.140139           -0.158118   \n",
       "\n",
       "                        Data_Scores_Aftertaste  Data_Scores_Acidity  \\\n",
       "Data_Scores_Aroma                     0.687381             0.583343   \n",
       "Data_Scores_Flavor                    0.867073             0.748506   \n",
       "Data_Scores_Aftertaste                1.000000             0.713362   \n",
       "Data_Scores_Acidity                   0.713362             1.000000   \n",
       "Data_Scores_Body                      0.644566             0.577561   \n",
       "Data_Scores_Balance                   0.774139             0.642226   \n",
       "Data_Scores_Uniformity                0.229603             0.189579   \n",
       "Data_Scores_Sweetness                 0.097145             0.072401   \n",
       "Data_Scores_Moisture                 -0.203983            -0.139417   \n",
       "\n",
       "                        Data_Scores_Body  Data_Scores_Balance  \\\n",
       "Data_Scores_Aroma               0.524785             0.616120   \n",
       "Data_Scores_Flavor              0.645804             0.740464   \n",
       "Data_Scores_Aftertaste          0.644566             0.774139   \n",
       "Data_Scores_Acidity             0.577561             0.642226   \n",
       "Data_Scores_Body                1.000000             0.697203   \n",
       "Data_Scores_Balance             0.697203             1.000000   \n",
       "Data_Scores_Uniformity          0.120972             0.238316   \n",
       "Data_Scores_Sweetness           0.053079             0.142841   \n",
       "Data_Scores_Moisture           -0.162159            -0.189901   \n",
       "\n",
       "                        Data_Scores_Uniformity  Data_Scores_Sweetness  \\\n",
       "Data_Scores_Aroma                     0.162246               0.046627   \n",
       "Data_Scores_Flavor                    0.240938               0.138560   \n",
       "Data_Scores_Aftertaste                0.229603               0.097145   \n",
       "Data_Scores_Acidity                   0.189579               0.072401   \n",
       "Data_Scores_Body                      0.120972               0.053079   \n",
       "Data_Scores_Balance                   0.238316               0.142841   \n",
       "Data_Scores_Uniformity                1.000000               0.372348   \n",
       "Data_Scores_Sweetness                 0.372348               1.000000   \n",
       "Data_Scores_Moisture                  0.024010               0.136506   \n",
       "\n",
       "                        Data_Scores_Moisture  \n",
       "Data_Scores_Aroma                  -0.140139  \n",
       "Data_Scores_Flavor                 -0.158118  \n",
       "Data_Scores_Aftertaste             -0.203983  \n",
       "Data_Scores_Acidity                -0.139417  \n",
       "Data_Scores_Body                   -0.162159  \n",
       "Data_Scores_Balance                -0.189901  \n",
       "Data_Scores_Uniformity              0.024010  \n",
       "Data_Scores_Sweetness               0.136506  \n",
       "Data_Scores_Moisture                1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flavor, Aftertaste, Acidity, Body, and Aroma all appear to have a relatively strong linear relationship based on their correlation values so there would be an issue with mulitcollinearity for this linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Non-Regularized Linear Regression Model\n",
    "\n",
    "### 2.1. Training the Model\n",
    "First, let's fit a non-regularized linear regression model using our training features matrix and target array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(train_feature, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Testing the Model\n",
    "\n",
    "Next, calculate the test R^2 of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700904635439342"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(test_feature, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LASSO Linear Regression Models\n",
    "\n",
    "\n",
    "### 3.1. Parameter Tuning\n",
    "\n",
    "Let's try to find the value of $\\lambda$ in a LASSO linear regression (that we will train with our training dataset) that *maximizes* the test $R^2$ value.\n",
    "\n",
    "1. In a for loop, iterate through a series of $\\lambda$ values that go from `[0,0.005, 0.01, 0.015, 0.02,..., 0.4]`.\n",
    "2. For each value of $\\lambda$ do the following.\n",
    "    * Train a LASSO linear regression model with the training dataset and this given $\\lambda$.\n",
    "    * Calculate the test R^2 value for this LASSO linear regression model.\n",
    "    \n",
    "Your final result of this problem should include a *dataframe* that has two columns:\n",
    "* the $\\lambda$ value\n",
    "* the test R^2 that correspond to this $\\lambda$ value.\n",
    "\n",
    "*Hint: See the tutorial above for code suggestions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diamo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diamo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diamo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+01, tolerance: 9.961e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda value</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.670090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.677014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.677281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.669437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.662257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.390</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda value       R^2\n",
       "0          0.000  0.670090\n",
       "1          0.005  0.677014\n",
       "2          0.010  0.677281\n",
       "3          0.015  0.669437\n",
       "4          0.020  0.662257\n",
       "..           ...       ...\n",
       "76         0.380 -0.000392\n",
       "77         0.385 -0.000392\n",
       "78         0.390 -0.000392\n",
       "79         0.395 -0.000392\n",
       "80         0.400 -0.000392\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_list=[]\n",
    "for i in np.arange(0, 0.405, 0.005):\n",
    "    temp = Lasso(alpha=i, max_iter=1000)\n",
    "    model = temp.fit(train_feature, train_target)\n",
    "    lambda_list.append([i, model.score(test_feature,test_target)])\n",
    "\n",
    "df_lasso_lambda = pd.DataFrame(lambda_list, columns=['lambda value', 'R^2'])\n",
    "df_lasso_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Test R^2 and $\\lambda$ Relationship\n",
    "\n",
    "Plot the relationship between the $\\lambda$ values and the Test R^2 in a **line plot**.\n",
    "\n",
    "*Hint: Your code might look something like this.*\n",
    "\n",
    "`plt.plot(df_output['lambda'].values, df_output['test_r2'].values)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_lasso_lambda['lambda value'].values, df_lasso_lambda['R^2'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Highest Test R^2\n",
    "\n",
    "Which of our fitted LASSO linear regression models do we think might perform the best when predicting coffee Balance for *new datasets*? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda value</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.670090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.677014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.677281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.669437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.662257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.390</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.000392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda value       R^2\n",
       "0          0.000  0.670090\n",
       "1          0.005  0.677014\n",
       "2          0.010  0.677281\n",
       "3          0.015  0.669437\n",
       "4          0.020  0.662257\n",
       "..           ...       ...\n",
       "76         0.380 -0.000392\n",
       "77         0.385 -0.000392\n",
       "78         0.390 -0.000392\n",
       "79         0.395 -0.000392\n",
       "80         0.400 -0.000392\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lasso_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph and the dataframe above, the LASSO linear regression model with lambda = .01 will perform the best when predicting Balance for new datasets since that model has the greatest R^2 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. LASSO Linear Regression Model Improvment\n",
    "\n",
    "Did our best LASSO linear regression model perform better than our nonregularized linear regression model with respect to our primary research goal? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best LASSO linear regression model performed better than the nonregularized linear regression model because its R^2 value = 0.677281 while the nonregularized linear regression model had an R^2 value of 0.6700904635439342."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. LASSO Slope Interpretation\n",
    "\n",
    "#### 3.5.1. Slopes\n",
    "Display the slopes of your best LASSO linear regression model. Make sure your code output is able to indicate which slope corrresponds to which explanatory variable in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slopes_lasso = pd.DataFrame({'lasso_reg_.01': Lasso(alpha=.01, max_iter=1000).fit(train_feature,train_target).coef_.T}, index=train_feature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_reg_.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <td>0.030082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <td>0.107870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <td>0.402550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <td>0.032515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <td>0.285672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <td>0.011769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <td>0.012519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        lasso_reg_.01\n",
       "Data_Scores_Aroma            0.030082\n",
       "Data_Scores_Flavor           0.107870\n",
       "Data_Scores_Aftertaste       0.402550\n",
       "Data_Scores_Acidity          0.032515\n",
       "Data_Scores_Body             0.285672\n",
       "Data_Scores_Uniformity       0.011769\n",
       "Data_Scores_Sweetness        0.012519\n",
       "Data_Scores_Moisture        -0.000000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slopes_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. Interpretation\n",
    "\n",
    "Are there any explanatory variables that this LASSO linear regression model is suggesting a.) do not bring enough predictive power to the model and b.) might be overfitting?\n",
    "\n",
    "If so, explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Moisture has a slope of 0 with the lambda value we are using in this LASSO linear regression model, it can be determined that the model might be overfitting by including it and that it does not bring enough predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. LASSO Linear Regression Multicollinearity\n",
    "\n",
    "Do the explanatory variables in your training features matrix that have non-zero slopes in your best LASSO linear regression model have an issue with multicollinearity? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.687381</td>\n",
       "      <td>0.583343</td>\n",
       "      <td>0.524785</td>\n",
       "      <td>0.162246</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>-0.140139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <td>0.725166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.645804</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.138560</td>\n",
       "      <td>-0.158118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <td>0.687381</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713362</td>\n",
       "      <td>0.644566</td>\n",
       "      <td>0.229603</td>\n",
       "      <td>0.097145</td>\n",
       "      <td>-0.203983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <td>0.583343</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.713362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577561</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>0.072401</td>\n",
       "      <td>-0.139417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <td>0.524785</td>\n",
       "      <td>0.645804</td>\n",
       "      <td>0.644566</td>\n",
       "      <td>0.577561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120972</td>\n",
       "      <td>0.053079</td>\n",
       "      <td>-0.162159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <td>0.162246</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.229603</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>0.120972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>0.024010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.138560</td>\n",
       "      <td>0.097145</td>\n",
       "      <td>0.072401</td>\n",
       "      <td>0.053079</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <td>-0.140139</td>\n",
       "      <td>-0.158118</td>\n",
       "      <td>-0.203983</td>\n",
       "      <td>-0.139417</td>\n",
       "      <td>-0.162159</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Data_Scores_Aroma  Data_Scores_Flavor  \\\n",
       "Data_Scores_Aroma                1.000000            0.725166   \n",
       "Data_Scores_Flavor               0.725166            1.000000   \n",
       "Data_Scores_Aftertaste           0.687381            0.867073   \n",
       "Data_Scores_Acidity              0.583343            0.748506   \n",
       "Data_Scores_Body                 0.524785            0.645804   \n",
       "Data_Scores_Uniformity           0.162246            0.240938   \n",
       "Data_Scores_Sweetness            0.046627            0.138560   \n",
       "Data_Scores_Moisture            -0.140139           -0.158118   \n",
       "\n",
       "                        Data_Scores_Aftertaste  Data_Scores_Acidity  \\\n",
       "Data_Scores_Aroma                     0.687381             0.583343   \n",
       "Data_Scores_Flavor                    0.867073             0.748506   \n",
       "Data_Scores_Aftertaste                1.000000             0.713362   \n",
       "Data_Scores_Acidity                   0.713362             1.000000   \n",
       "Data_Scores_Body                      0.644566             0.577561   \n",
       "Data_Scores_Uniformity                0.229603             0.189579   \n",
       "Data_Scores_Sweetness                 0.097145             0.072401   \n",
       "Data_Scores_Moisture                 -0.203983            -0.139417   \n",
       "\n",
       "                        Data_Scores_Body  Data_Scores_Uniformity  \\\n",
       "Data_Scores_Aroma               0.524785                0.162246   \n",
       "Data_Scores_Flavor              0.645804                0.240938   \n",
       "Data_Scores_Aftertaste          0.644566                0.229603   \n",
       "Data_Scores_Acidity             0.577561                0.189579   \n",
       "Data_Scores_Body                1.000000                0.120972   \n",
       "Data_Scores_Uniformity          0.120972                1.000000   \n",
       "Data_Scores_Sweetness           0.053079                0.372348   \n",
       "Data_Scores_Moisture           -0.162159                0.024010   \n",
       "\n",
       "                        Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "Data_Scores_Aroma                    0.046627             -0.140139  \n",
       "Data_Scores_Flavor                   0.138560             -0.158118  \n",
       "Data_Scores_Aftertaste               0.097145             -0.203983  \n",
       "Data_Scores_Acidity                  0.072401             -0.139417  \n",
       "Data_Scores_Body                     0.053079             -0.162159  \n",
       "Data_Scores_Uniformity               0.372348              0.024010  \n",
       "Data_Scores_Sweetness                1.000000              0.136506  \n",
       "Data_Scores_Moisture                 0.136506              1.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from Uniformity and Sweetness, all the explanatory variables could have an issue with multicollinearity as their correlation values with other explanatory variables are relatively high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Ridge Regression Models\n",
    "\n",
    "\n",
    "### 4.1. Parameter Tuning\n",
    "\n",
    "Next, let's try to find the value of $\\lambda$ in a linear ridge regression (that we will train with our training dataset) that *maximizes* the test $R^2$ value.\n",
    "\n",
    "1. In a for loop, iterate through a series of $\\lambda$ values that go from `[0,1,2,3,..., 400]`.\n",
    "2. For each value of $\\lambda$ do the following.\n",
    "    * Train a linear ridge regression model with the training dataset and this given $\\lambda$.\n",
    "    * Calculate the test R^2 value for this linear ridge regression model.\n",
    "    \n",
    "Your final result of this problem should include a *dataframe* that has two columns:\n",
    "* the $\\lambda$ value\n",
    "* the test R^2 that correspond to this $\\lambda$ value.\n",
    "\n",
    "*Hint: See the tutorial above for code suggestions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda value</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.670090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.672198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.674130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.675940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.677625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>0.516678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>0.516202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>0.515726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>0.515251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>0.514777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lambda value       R^2\n",
       "0               0  0.670090\n",
       "1               1  0.672198\n",
       "2               2  0.674130\n",
       "3               3  0.675940\n",
       "4               4  0.677625\n",
       "..            ...       ...\n",
       "396           396  0.516678\n",
       "397           397  0.516202\n",
       "398           398  0.515726\n",
       "399           399  0.515251\n",
       "400           400  0.514777\n",
       "\n",
       "[401 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_list=[]\n",
    "for i in np.arange(0,401,1):\n",
    "    tempridge = Ridge(alpha=i, max_iter=1000)\n",
    "    model = tempridge.fit(train_feature, train_target)\n",
    "    ridge_list.append([i, model.score(test_feature,test_target)])\n",
    "df_ridge_lambda = pd.DataFrame(ridge_list, columns=['lambda value', 'R^2'])\n",
    "df_ridge_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Test R^2 and $\\lambda$ Relationship\n",
    "\n",
    "Plot the relationship between the $\\lambda$ values and the Test R^2 in a **line plot**.\n",
    "\n",
    "*Hint: Your code might look something like this.*\n",
    "\n",
    "`plt.plot(df_output['lambda'].values, df_output['test_r2'].values)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_ridge_lambda['lambda value'].values, df_ridge_lambda['R^2'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Highest Test R^2\n",
    "\n",
    "Which of our fitted linear ridge regression models do we think might perform the best when predicting coffee balance for *new datasets*? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda value</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.696714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.696722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.696714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda value       R^2\n",
       "38            38  0.696714\n",
       "39            39  0.696722\n",
       "40            40  0.696714"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ridge_lambda.max() #.696722\n",
    "df_ridge_lambda[df_ridge_lambda['R^2'] > .6967]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted linear ridge regression model with a lambda value of 39 and and R^2 value of .696722 will perform the best when predicting coffee balance for new datasets because it has the highest R^2 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Linear Regression Model Improvment\n",
    "\n",
    "Did our best linear ridge regression model perform better than our nonregularized linear regression model and our best LASSO linear regression model with respect to our primary research goal? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ridge linear regression model had an R^2 value of .696722 which was higher than the nonregularized model's R^2 value of 0.6700904635439342 and the LASSO model's value of 0.677281, it can be said that the linear ridge regression model performed better than the other two models when it comes to predicting the balance of coffee in new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Ridge Regression Slope Interpretation\n",
    "\n",
    "#### 4.5.1. Slopes\n",
    "Display the slopes of the following models in a dataframe. \n",
    "* Non-regularized linear regression model\n",
    "* Best LASSO linear regression model\n",
    "* Best linear ridge regression model\n",
    "\n",
    "Make sure your dataframe indicates what explanatory variable each slope corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slopes_all = pd.DataFrame({'lasso_reg_.01': Lasso(alpha=.01, max_iter=1000).fit(train_feature,train_target).coef_.T,'ridge_reg_39': Ridge(alpha=39, max_iter=1000).fit(train_feature,train_target).coef_.T, 'nonreg_lin': linreg.coef_.T}, index=train_feature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_reg_.01</th>\n",
       "      <th>ridge_reg_39</th>\n",
       "      <th>nonreg_lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.093098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <td>0.107870</td>\n",
       "      <td>0.160540</td>\n",
       "      <td>0.075766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <td>0.402550</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>0.382284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <td>0.032515</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <td>0.285672</td>\n",
       "      <td>0.237967</td>\n",
       "      <td>0.355667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <td>0.012519</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.032439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.019005</td>\n",
       "      <td>-0.301375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        lasso_reg_.01  ridge_reg_39  nonreg_lin\n",
       "Data_Scores_Aroma            0.030082      0.115031    0.093098\n",
       "Data_Scores_Flavor           0.107870      0.160540    0.075766\n",
       "Data_Scores_Aftertaste       0.402550      0.246896    0.382284\n",
       "Data_Scores_Acidity          0.032515      0.118489    0.079925\n",
       "Data_Scores_Body             0.285672      0.237967    0.355667\n",
       "Data_Scores_Uniformity       0.011769      0.038571    0.034800\n",
       "Data_Scores_Sweetness        0.012519      0.027197    0.032439\n",
       "Data_Scores_Moisture        -0.000000     -0.019005   -0.301375"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slopes_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2. Slope Reduction\n",
    "\n",
    "Create a new column in this dataframe which represents your:\n",
    "$\\frac{mbox{ridge regression slopes}}{mbox{corresponding nonregularized linear regression slopes}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_reg_.01</th>\n",
       "      <th>ridge_reg_39</th>\n",
       "      <th>nonreg_lin</th>\n",
       "      <th>ridgeSlopes/nonregSlopes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.093098</td>\n",
       "      <td>1.235594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <td>0.107870</td>\n",
       "      <td>0.160540</td>\n",
       "      <td>0.075766</td>\n",
       "      <td>2.118888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <td>0.402550</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>0.382284</td>\n",
       "      <td>0.645844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <td>0.032515</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.079925</td>\n",
       "      <td>1.482513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <td>0.285672</td>\n",
       "      <td>0.237967</td>\n",
       "      <td>0.355667</td>\n",
       "      <td>0.669071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>1.108388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <td>0.012519</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.838419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.019005</td>\n",
       "      <td>-0.301375</td>\n",
       "      <td>0.063061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        lasso_reg_.01  ridge_reg_39  nonreg_lin  \\\n",
       "Data_Scores_Aroma            0.030082      0.115031    0.093098   \n",
       "Data_Scores_Flavor           0.107870      0.160540    0.075766   \n",
       "Data_Scores_Aftertaste       0.402550      0.246896    0.382284   \n",
       "Data_Scores_Acidity          0.032515      0.118489    0.079925   \n",
       "Data_Scores_Body             0.285672      0.237967    0.355667   \n",
       "Data_Scores_Uniformity       0.011769      0.038571    0.034800   \n",
       "Data_Scores_Sweetness        0.012519      0.027197    0.032439   \n",
       "Data_Scores_Moisture        -0.000000     -0.019005   -0.301375   \n",
       "\n",
       "                        ridgeSlopes/nonregSlopes  \n",
       "Data_Scores_Aroma                       1.235594  \n",
       "Data_Scores_Flavor                      2.118888  \n",
       "Data_Scores_Aftertaste                  0.645844  \n",
       "Data_Scores_Acidity                     1.482513  \n",
       "Data_Scores_Body                        0.669071  \n",
       "Data_Scores_Uniformity                  1.108388  \n",
       "Data_Scores_Sweetness                   0.838419  \n",
       "Data_Scores_Moisture                    0.063061  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slopes_all['ridgeSlopes/nonregSlopes'] = df_slopes_all['ridge_reg_39']/df_slopes_all['nonreg_lin']\n",
    "df_slopes_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Interpretation\n",
    "\n",
    "Which regularization model (LASSO vs. ridge regression) is it easier to interpret which explanatory variables bring enough predictive power to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO because it has an explanatory variable whose slope is 0 whereas the ridge regression doesn't, indicating that the LASSO model is accounting for the predictive power of each explanatory variable more than the ridge regression model and reducing the possibility of overfitting in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4. Slope Reduction Interpretation\n",
    "\n",
    "Which of our ridge regression slope absolute values decreased the most in comparison to it's corresponding original non-regularized linear regression model slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moisture because its ratio between the ridgeSlope : nonregSlope is the closest to 0 indicating that the ridge regression slope value is significantly smaller compared to the nonregularized regression slope value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
